apiVersion: v1
kind: Pod
metadata:
  namespace: spatiotemporal-decision-making
  name: muscle-simulation-pod
spec:
  affinity:
    nodeAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 1
          preference:
            matchExpressions:
            - key: nautilus.io/group
              operator: In
              values:
              - ry
  tolerations:
  - key: "nautilus.io/ry-reservation"
    operator: "Equal"
    value: "true"
    effect: "NoSchedule"
  imagePullSecrets:
    - name: shubh-gitlab-registry
  containers:
  - name: shubh-container
    image: gitlab-registry.nrp-nautilus.io/shmaheshwari/sports-analytics:latest
    imagePullPolicy: Always
    command: ["/bin/bash", "-c"]
    args: 
    - | 
      conda init bash && # Use bash instead of sh to run the script
      source ~/.bashrc &&

      conda activate opencap-processing
      pip install tqdm

      # Link the data folder to the mounted data folder
      cd /opencap-processing
      ln -sf /mnt/data/MCS_DATA/Data Data

      echo 'API_TOKEN="${API_TOKEN}"' > /opencap-processing/.env

      cd /opencap-processing/Examples
      python kubernetes_api.py --subject ${SUBJECT_ID} --mot-dir /mnt/data/MCS_DATA/Data/${SUBJECT_ID}/OpenSimData/Kinematics --segments /mnt/data/MCS_DATA/squat-segmentation-data/${SUBJECT_ID}.npy#  

      sleep 10000

    env: 
    - name: API_TOKEN
      value: "${API_TOKEN}"

    volumeMounts:
    - mountPath: /dev/shm
      name: dshm
    - mountPath: /mnt/data
      name: sports-analytics-database
    resources:
      limits:
        nvidia.com/gpu: "0"
        memory: "12Gi"
        cpu: "16"
      requests:
        nvidia.com/gpu: "0"
        memory: "16Gi"
        cpu: "32"
  volumes:
  - name: dshm
    emptyDir:
      medium: Memory
  - name: sports-analytics-database
    persistentVolumeClaim:
      claimName: sports-analytics-database
  restartPolicy: Never